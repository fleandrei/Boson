{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "csv_flie=\"atlas-higgs-challenge-2014-v2.csv\"\n",
    "crossval_num=3\n",
    "crossval=np.array(crossval_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Cust(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, train=True, crossval_nbr=3, transformation=None):\n",
    "        'Initialization'\n",
    "        self.all=np.array(pd.read_csv(csv_file))\n",
    "        #print(self.all[:,:-3])\n",
    "        self.data=torch.from_numpy(self.all[:,0:-3].astype('float64'))\n",
    "        self.train=train\n",
    "        \n",
    "        self.crossval_nbr=crossval_nbr\n",
    "        self.testpart_num=crossval_nbr-1\n",
    "        \n",
    "        self.nbrpoint=len(self.all)\n",
    "        #self.nbrtrain=int((1-1/crossval_nbr)*self.nbrpoint)\n",
    "        \n",
    "        self.Taille_section=int(self.nbrpoint/self.crossval_nbr)\n",
    "        self.debut_test=self.testpart_num * self.Taille_section\n",
    "        \n",
    "        if self.testpart_num==self.crossval_nbr-1:\n",
    "            self.fin_test=self.nbrpoint\n",
    "        else:\n",
    "            self.fin_test=self.debut_test + self.Taille_section\n",
    "        \n",
    "        self.nbrtest=self.fin_test - self.debut_test\n",
    "        self.nbrtrain=self.nbrpoint - self.nbrtest\n",
    "        #self.numtest=self.numpoint - self.numtrain\n",
    "        \n",
    "        self.transformation=transformation\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        if self.train:\n",
    "            return self.nbrtrain\n",
    "        else:\n",
    "            return self.fin_test - self.debut_test\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        if self.train:\n",
    "            if index>= self.debut_test:\n",
    "                index+=self.nbrtest\n",
    "                \n",
    "        else:\n",
    "            index+=self.debut_test\n",
    "        \n",
    "        #sample=torch.from_numpy(self.all[index][0:-3].astype('float64'))\n",
    "        sample=self.data[index]\n",
    "        sample.requires_grad=True\n",
    "        label=1 if self.all[index][-3]==\"s\" else 0\n",
    "        \n",
    "        if self.transformation :\n",
    "            sample=self.transformation(sample)\n",
    "\n",
    "        return sample.float(), float(label)\n",
    "    \n",
    "    def Set_Train(self, train):\n",
    "        self.train=train\n",
    "        \n",
    "    def Set_TestPart_Num(self,num):\n",
    "        self.testpart_num=num\n",
    "        \n",
    "        self.debut_test=self.testpart_num * self.Taille_section\n",
    "        \n",
    "        if self.testpart_num==self.crossval_nbr-1:\n",
    "            self.fin_test=self.nbrpoint\n",
    "        else:\n",
    "            self.fin_test=self.debut_test + self.Taille_section\n",
    "        \n",
    "        self.nbrtest=self.fin_test - self.debut_test\n",
    "        self.nbrtrain=self.nbrpoint - self.nbrtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=Dataset_Cust(csv_flie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Loader=torch.utils.data.DataLoader(Dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1=nn.Conv1d(1,10,5)\n",
    "        self.conv2=nn.Conv1d(10,20,5)\n",
    "        self.fc=nn.Linear(50*4*4,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=F.max_pool1d(F.relu(self.conv1(x)),2,2)\n",
    "        x=F.max_pool1d(F.relu(self.conv2(x)),2,2)\n",
    "        x=x.view(-1,50*4*4)\n",
    "        x=self.fc(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.BCELoss()\n",
    "optimizeCnn= optim.SGD(Cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(Model, Optimizer, Criterion, Data_Loader,Epoch=10, log_interval=100):\n",
    "    #Data_Loader.dataset.Set_TestPart_Num(4)\n",
    "    print(Data_Loader.dataset.debut_test)\n",
    "    predicted=np.empty(batch_size)\n",
    "    #print(type(Percep.fc1.weight[0][0].item()))\n",
    "    #print(type(Percep.fc1.bias[0].item()))\n",
    "    init_weights(Model)\n",
    "    \n",
    "    Data_Loader.dataset.train=True\n",
    "    \n",
    "    for epoch in range(Epoch):\n",
    "        ams=0\n",
    "        TP=0 #True Positive\n",
    "        FP=0 # False Positive\n",
    "        S=0 #True Positive pondéré\n",
    "        B=0 # False Positive pondéré\n",
    "        Loss=0\n",
    "        correct=0\n",
    "    \n",
    "        fp=0\n",
    "        tp=0\n",
    "        total=0\n",
    "        running_loss=0\n",
    "        for batch_id, sample in enumerate(Data_Loader,0):\n",
    "            inputs, labels= sample\n",
    "            Optimizer.zero_grad()\n",
    "            \n",
    "            #print(inputs[0][0].requires_grad)\n",
    "            #print(labels.size(0))\n",
    "            #print(inputs[0][0])\n",
    "            \n",
    "            \n",
    "            outputs= Model(inputs[:,1:31])\n",
    "        \n",
    "             #print(outputs[0]+outputs[1])\n",
    "             # print(outputs.view(-1,32))\n",
    "            \n",
    "            #predicted= torch.tensor(1 if outputs.data[j] > 0.5 else 0 for j in range(len(outputs.data)))\n",
    "            total+= labels.size(0)\n",
    "            #correct+= (predicted== labels).sum().item()\n",
    "            for i in range(labels.size(0)):\n",
    "                if outputs.data[i]>0.5:\n",
    "                    predicted[i]=1\n",
    "                    if labels[i]==1:\n",
    "                        TP+=1\n",
    "                        tp+=1\n",
    "                        S+= inputs[i][31]\n",
    "                        correct+=1\n",
    "                    else:\n",
    "                        FP+=1\n",
    "                        fp+=1\n",
    "                        B+=inputs[i][31]\n",
    "                else:\n",
    "                    predicted[i]=0\n",
    "                    if labels[i]==0:\n",
    "                        correct+=1\n",
    "            \n",
    "        \n",
    "            #print(outputs)\n",
    "            #outputs=outputs.view(-1,10)\n",
    "            loss= Criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            Optimizer.step()\n",
    "        \n",
    "            running_loss+= loss.item()\n",
    "            Loss+=loss.item()\n",
    "            if batch_id%log_interval==0:\n",
    "                if tp+fp>0:\n",
    "                    print(\"epoch:{}, nombre batch:{} loss:{:.3f} precision={:.3f}%\".format(epoch+1, batch_id+1, running_loss/log_interval, 100*tp/(tp+fp))) \n",
    "                else:\n",
    "                    print(\"epoch:{}, nombre batch:{} loss:{:.3f} \".format(epoch+1, batch_id+1, running_loss/log_interval)) \n",
    "\n",
    "                total=0\n",
    "                tp=0\n",
    "                fp=0\n",
    "                running_loss=0\n",
    "        if TP+FP>0:\n",
    "            print(\"Resultat Epoch {};  loss:{:.3f}, Accuracy={:.3f}  precision:{:.3f}%, AMS={:.4f}\".format(epoch+1, Loss/(batch_id+1), 100*correct/len(Data_Loader.dataset), 100*TP/(TP+FP), AMS(S,B) ))\n",
    "        else:\n",
    "            print(\"Resultat Epoch {};  loss:{:.3f}, Accuracy={:.3f}  , AMS={:.4f}\".format(epoch+1, Loss/(batch_id+1), 100*correct/len(Data_Loader.dataset), AMS(S,B) ))\n",
    "        \n",
    "    print(\"Résultat Entrainement: {} bonnes classification sur {} données :loss moyen/batch={:.4f}, Accuracy={:.3f},  precision={:.3f}%, AMS={:.4f}\".format(correct,len(Data_Loader.dataset), Loss/(batch_id+1), 100*correct/len(Data_Loader.dataset) ,100*TP/(TP+FP), AMS(S,B)))\n",
    "    return [Loss/(batch_id+1), 100*correct/len(Data_Loader.dataset), 100*TP/(TP+FP), AMS(S,B) ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(Model, Criterion, Data_Loader):\n",
    "    #TEST Perceptron\n",
    "\n",
    "    correct= 0\n",
    "    total= 0\n",
    "    test_loss = 0\n",
    "    predicted=np.empty(batch_size)\n",
    "    TP=0\n",
    "    FP=0\n",
    "    S=0\n",
    "    B=0\n",
    "\n",
    "    Data_Loader.dataset.train=False\n",
    "    with torch.no_grad():\n",
    "        for sample in Data_Loader:\n",
    "            inputs, labels= sample\n",
    "            #images=images.view(-1,784)\n",
    "            outputs= Model(inputs[:,1:31])\n",
    "\n",
    "            total+= labels.size(0)\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                    if outputs.data[i]>0.5:\n",
    "                        predicted[i]=1\n",
    "\n",
    "                        if labels[i]==1:\n",
    "                            TP+=1\n",
    "                            #tp+=1\n",
    "                            S+= inputs[i][31]\n",
    "                            correct+=1\n",
    "                        else:\n",
    "                            FP+=1\n",
    "                            #fp+=1\n",
    "                            B+=inputs[i][31]\n",
    "                    else:\n",
    "                        predicted[i]=0\n",
    "                        if labels[i]==0:\n",
    "                            correct+=1\n",
    "\n",
    "            test_loss+=Criterion(outputs,labels.float())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_loss/= len(Data_Loader.dataset)\n",
    "\n",
    "    print(\"Résultat test: {} bonnes classification sur {} données de test:loss moyen={:.8f} Accuracy={:.3f}%, Precision={:.3f}%, AMS={:.3f}\".format(correct,total, test_loss/total,100*correct/total, 100*TP/(TP+FP), AMS(S,B)))\n",
    "    \n",
    "    return [test_loss/total, 100*correct/total, 100*TP/(TP+FP), AMS(S,B)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight 10 1 5, but got 2-dimensional input of size [32, 30] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-444814deb41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mCnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m#print(outputs[0]+outputs[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8f9a52e7be51>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight 10 1 5, but got 2-dimensional input of size [32, 30] instead"
     ]
    }
   ],
   "source": [
    "#TRAIN CNN\n",
    "\n",
    "Epoch=10\n",
    "\n",
    "log_interval=100\n",
    "predicted=np.empty(batch_size)\n",
    "#print(type(Percep.fc1.weight[0][0].item()))\n",
    "#print(type(Percep.fc1.bias[0].item()))\n",
    "for epoch in range(Epoch):\n",
    "    ams=0\n",
    "    TP=0 #True Positive\n",
    "    FP=0 # False Positive\n",
    "    S=0 #True Positive pondéré\n",
    "    B=0 # False Positive pondéré\n",
    "    Loss=0\n",
    "    correct=0\n",
    "    \n",
    "    fp=0\n",
    "    tp=0\n",
    "    total=0\n",
    "    running_loss=0\n",
    "    for batch_id, sample in enumerate(Train_Loader,0):\n",
    "            inputs, labels= sample\n",
    "            optimizeCnn.zero_grad()\n",
    "            \n",
    "            #print(inputs)\n",
    "            #print(labels.size(0))\n",
    "            \n",
    "            \n",
    "            \n",
    "            outputs= Cnn(inputs[:,1:31])\n",
    "            \n",
    "            #print(outputs[0]+outputs[1])\n",
    "           # print(outputs.view(-1,32))\n",
    "        \n",
    "            #predicted= torch.tensor(1 if outputs.data[j] > 0.5 else 0 for j in range(len(outputs.data)))\n",
    "            total+= labels.size(0)\n",
    "            #correct+= (predicted== labels).sum().item()\n",
    "            for i in range(labels.size(0)):\n",
    "                if outputs.data[i]>0.5:\n",
    "                    predicted[i]=1\n",
    "            \n",
    "                    if labels[i]==1:\n",
    "                        TP+=1\n",
    "                        tp+=1\n",
    "                        S+= inputs[i][31]\n",
    "                        correct+=1\n",
    "                    else:\n",
    "                        FP+=1\n",
    "                        fp+=1\n",
    "                        B+=inputs[i][31]\n",
    "                else:\n",
    "                    predicted[i]=0\n",
    "                    if labels[i]==0:\n",
    "                        correct+=1\n",
    "            \n",
    "        \n",
    "            #print(outputs)\n",
    "            #outputs=outputs.view(-1,10)\n",
    "            loss= criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizeCnn.step()\n",
    "        \n",
    "            running_loss+= loss.item()\n",
    "            Loss+=loss.item()\n",
    "            if batch_id%log_interval==0:\n",
    "                print(\"epoch:{}, nombre batch:{} loss:{:.3f} precision={:.3f}%\".format(epoch+1, batch_id+1, running_loss/log_interval, 100*tp/(tp+fp))) \n",
    "                total=0\n",
    "                tp=0\n",
    "                fp=0\n",
    "                running_loss=0\n",
    "    print(\"Resultat Epoch {};  loss:{:.3f}, Accuracy={:.3f}%,  precision:{:.3f}%, AMS={:.4f}\".format(epoch+1, Loss/(batch_id+1), 100*correct/len(Train_Loader.dataset), 100*TP/(TP+FP), AMS(S,B) ))\n",
    "   \n",
    "        \n",
    "print(\"Résultat Entrainement: {} bonnes classification sur {} données :loss moyen/batch={:.4f}, Accuracy={:.3f}%,  precision={:.3f}%, AMS={:.4f}\".format(correct,len(Train_Loader.dataset), Loss/(batch_id+1), 100*correct/len(Train_Loader.dataset) ,100*TP/(TP+FP), AMS(S,B)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
